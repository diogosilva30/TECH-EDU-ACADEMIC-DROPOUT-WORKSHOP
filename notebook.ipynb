{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9j_0bRdBk03"
      },
      "source": [
        "# Import the required dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUjA3_71AG7L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d67e1e8-4152-496c-e267-576b0f85041b"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/tensorflow/docs\n",
            "  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-s44dn0w2\n",
            "  Running command git clone -q https://github.com/tensorflow/docs /tmp/pip-req-build-s44dn0w2\n",
            "Requirement already satisfied (use --upgrade to upgrade): tensorflow-docs===0.0.05dfd89e64eba8083f1978bdb826b7ca7c42a8bca- from git+https://github.com/tensorflow/docs in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.6/dist-packages (from tensorflow-docs===0.0.05dfd89e64eba8083f1978bdb826b7ca7c42a8bca-) (0.8.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow-docs===0.0.05dfd89e64eba8083f1978bdb826b7ca7c42a8bca-) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.14 in /usr/local/lib/python3.6/dist-packages (from tensorflow-docs===0.0.05dfd89e64eba8083f1978bdb826b7ca7c42a8bca-) (3.14.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from tensorflow-docs===0.0.05dfd89e64eba8083f1978bdb826b7ca7c42a8bca-) (3.13)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from tensorflow-docs===0.0.05dfd89e64eba8083f1978bdb826b7ca7c42a8bca-) (0.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py->tensorflow-docs===0.0.05dfd89e64eba8083f1978bdb826b7ca7c42a8bca-) (1.15.0)\n",
            "Building wheels for collected packages: tensorflow-docs\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-docs: filename=tensorflow_docs-0.0.05dfd89e64eba8083f1978bdb826b7ca7c42a8bca_-cp36-none-any.whl size=146356 sha256=a8c09db72cdf0a7980d22d340d06c0b42308f7494c1d5245fdbb700f94c01db8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jo3g1oj4/wheels/eb/1b/35/fce87697be00d2fc63e0b4b395b0d9c7e391a10e98d9a0d97f\n",
            "Successfully built tensorflow-docs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnXLT5_3BOqp"
      },
      "source": [
        "# 1. Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tJBI0jdAd-V"
      },
      "source": [
        "# Read the dataset in excel format\r\n",
        "# index_col is the column that should be used for indexing the students (student id)\r\n",
        "dataset = pd.read_excel('dataset.xlsx', index_col='aluno')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQLUNjUWBbN9"
      },
      "source": [
        "## Understanding the dataset structure\r\n",
        "First it's important to take a look on how the data is structured"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5moSXxVBeL_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2c53b6cc-2b56-4b78-fda9-3175245318a8"
      },
      "source": [
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idade</th>\n",
              "      <th>nomeconcelho</th>\n",
              "      <th>paigse</th>\n",
              "      <th>painesc</th>\n",
              "      <th>paiprofissao</th>\n",
              "      <th>maegse</th>\n",
              "      <th>maenesc</th>\n",
              "      <th>maeprofissao</th>\n",
              "      <th>sexo</th>\n",
              "      <th>Desistencia</th>\n",
              "      <th>ALGEBRA LINEAR</th>\n",
              "      <th>ANALISE MATEMATICA I</th>\n",
              "      <th>ANALISE MATEMATICA II</th>\n",
              "      <th>ARQUITETURA DE COMPUTADORES</th>\n",
              "      <th>INGLES E TECNICAS DE COMUNICAC?O I</th>\n",
              "      <th>INGLES E TECNICAS DE COMUNICAC?O II</th>\n",
              "      <th>INTRODUC?O A ENGENHARIA INFORMATICA</th>\n",
              "      <th>LABORATORIO INTEGRADO I</th>\n",
              "      <th>LOGICA COMPUTACIONAL</th>\n",
              "      <th>METODOLOGIAS DE PROGRAMAC?O I</th>\n",
              "      <th>SEMINARIO DE INFORMATICA</th>\n",
              "      <th>SISTEMAS DIGITAIS</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aluno</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>26033751975</th>\n",
              "      <td>27</td>\n",
              "      <td>VILA REAL</td>\n",
              "      <td>Desconhecido / N?o tem</td>\n",
              "      <td>4? ano de escolaridade (antiga 4? classe)</td>\n",
              "      <td>Desconhece</td>\n",
              "      <td>Desconhecido / N?o tem</td>\n",
              "      <td>4? ano de escolaridade (antiga 4? classe)</td>\n",
              "      <td>Desconhece</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>13</td>\n",
              "      <td>11.0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25621666917</th>\n",
              "      <td>29</td>\n",
              "      <td>SEM CONCELHO</td>\n",
              "      <td>Operarios de instalac?es e maquinas</td>\n",
              "      <td>4? ano de escolaridade (antiga 4? classe)</td>\n",
              "      <td>Desconhece</td>\n",
              "      <td>Especialistas das profiss?es intelectuais e ci...</td>\n",
              "      <td>Ensino superior (bacharelato, licenciatura)</td>\n",
              "      <td>Desconhece</td>\n",
              "      <td>M</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25697772716</th>\n",
              "      <td>27</td>\n",
              "      <td>SEM CONCELHO</td>\n",
              "      <td>Desconhecido / N?o tem</td>\n",
              "      <td>Ensino secundario complementar ou equivalente ...</td>\n",
              "      <td>Outra situac?o</td>\n",
              "      <td>Desconhecido / N?o tem</td>\n",
              "      <td>Ensino secundario complementar ou equivalente ...</td>\n",
              "      <td>Outra situac?o</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>13</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25796153383</th>\n",
              "      <td>29</td>\n",
              "      <td>VILA REAL</td>\n",
              "      <td>Pessoal das Forcas Armadas</td>\n",
              "      <td>9? ano de escolaridade (antigo 5? ano)</td>\n",
              "      <td>Desconhece</td>\n",
              "      <td>Especialistas das profiss?es intelectuais e ci...</td>\n",
              "      <td>Ensino secundario complementar ou equivalente ...</td>\n",
              "      <td>Desconhece</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>14</td>\n",
              "      <td>14.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>10</td>\n",
              "      <td>10.0</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25896390289</th>\n",
              "      <td>31</td>\n",
              "      <td>SEM CONCELHO</td>\n",
              "      <td>Outra situac?o</td>\n",
              "      <td>4? ano de escolaridade (antiga 4? classe)</td>\n",
              "      <td>Desconhece</td>\n",
              "      <td>Aluno, estudante</td>\n",
              "      <td>9? ano de escolaridade (antigo 5? ano)</td>\n",
              "      <td>Desconhece</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>14</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>16</td>\n",
              "      <td>14.0</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93131223108</th>\n",
              "      <td>22</td>\n",
              "      <td>SANTA MARTA DE PENAGUI?O</td>\n",
              "      <td>Trabalhador por conta de outrem</td>\n",
              "      <td>Ensino secundario complementar ou equivalente ...</td>\n",
              "      <td>Desconhece</td>\n",
              "      <td>Trabalhador por conta de outrem</td>\n",
              "      <td>Ensino secundario complementar ou equivalente ...</td>\n",
              "      <td>Desconhece</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92826799912</th>\n",
              "      <td>22</td>\n",
              "      <td>SEM CONCELHO</td>\n",
              "      <td>Trabalhador por conta de outrem</td>\n",
              "      <td>9? ano de escolaridade (antigo 5? ano)</td>\n",
              "      <td>Trabalhadores qualificados da industria, const...</td>\n",
              "      <td>Desempregado</td>\n",
              "      <td>9? ano de escolaridade (antigo 5? ano)</td>\n",
              "      <td>Trabalhadores n?o qualificados</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92928893057</th>\n",
              "      <td>21</td>\n",
              "      <td>SEM CONCELHO</td>\n",
              "      <td>Trabalhador por conta propria como isolado</td>\n",
              "      <td>9? ano de escolaridade (antigo 5? ano)</td>\n",
              "      <td>Pessoal administrativo</td>\n",
              "      <td>Trabalhador por conta propria como isolado</td>\n",
              "      <td>Ensino secundario complementar ou equivalente ...</td>\n",
              "      <td>Pessoal administrativo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92865780931</th>\n",
              "      <td>23</td>\n",
              "      <td>VILA POUCA DE AGUIAR</td>\n",
              "      <td>Reformado</td>\n",
              "      <td>4? ano de escolaridade (antiga 4? classe)</td>\n",
              "      <td>Outra situac?o</td>\n",
              "      <td>Domestico</td>\n",
              "      <td>4? ano de escolaridade (antiga 4? classe)</td>\n",
              "      <td>Outra situac?o</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92982723988</th>\n",
              "      <td>22</td>\n",
              "      <td>SEM CONCELHO</td>\n",
              "      <td>Trabalhador por conta propria como isolado</td>\n",
              "      <td>6? ano de escolaridade (antigo 2? ano ou ciclo...</td>\n",
              "      <td>Outra situac?o</td>\n",
              "      <td>Trabalhador por conta de outrem</td>\n",
              "      <td>6? ano de escolaridade (antigo 2? ano ou ciclo...</td>\n",
              "      <td>Outra situac?o</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>325 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             idade  ... SISTEMAS DIGITAIS\n",
              "aluno               ...                  \n",
              "26033751975     27  ...                14\n",
              "25621666917     29  ...                 0\n",
              "25697772716     27  ...                12\n",
              "25796153383     29  ...                13\n",
              "25896390289     31  ...                 0\n",
              "...            ...  ...               ...\n",
              "93131223108     22  ...                18\n",
              "92826799912     22  ...                17\n",
              "92928893057     21  ...                10\n",
              "92865780931     23  ...                14\n",
              "92982723988     22  ...                10\n",
              "\n",
              "[325 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y87g7O6hF1Es"
      },
      "source": [
        "# 2. Cleaning the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gReDp-jr9s07"
      },
      "source": [
        "## 2.1 Handling missing values\r\n",
        "First we need to find out which columns have missing values (NaN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AxcuWHPF3gN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34b2b76b-560a-4221-e38c-66da8c30d223"
      },
      "source": [
        "# Here we find out that the sex column is the only one with missing values\r\n",
        "missing_values_columns=dataset.columns[dataset.isna().any()].tolist()\r\n",
        "print(f\"Columns with missing values (NaN): {missing_values_columns}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Columns with missing values (NaN): ['sexo']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tjZUd9aGMZl"
      },
      "source": [
        "### 2.1.1 Filling the 'Sex' Column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iPV5skm_YAw"
      },
      "source": [
        "Let's find how much data is missing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TohIarInGTeO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db5a17b5-db49-4650-d0e8-fbb0fb8d5222"
      },
      "source": [
        "missing = dataset[\"sexo\"].isnull().sum(axis=0)\r\n",
        "total = dataset.shape[0]\r\n",
        "\r\n",
        "print(f\"Percentage of missin values in the column 'sexo': {(missing*100)/total:.2f} %\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of missin values in the column 'sexo': 43.38 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDUQApEu_pzD"
      },
      "source": [
        "For filling the missing values of this column, we will use a simple yet effective strategy. We will replace all the missing values with the most frequent one. For this we can use [SimpleImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html) from scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzA_N2QNAii7"
      },
      "source": [
        "# Import the 'SimpleImputer' module\r\n",
        "from sklearn.impute import SimpleImputer\r\n",
        "\r\n",
        "\r\n",
        "# Create an imputer object with the 'most_frequent' strategy.\r\n",
        "# Here we also specify that the missing values are 'NaN'\r\n",
        "# verbose 0 means no logging\r\n",
        "imp_most_frequent = SimpleImputer(missing_values=np.nan, strategy='most_frequent', verbose=0)\r\n",
        "\r\n",
        "# We apply this method to the sex column\r\n",
        "# We need to perform the reshape because this method expects a 2D array\r\n",
        "# and we are only passing 1 column. So we need to make it a 2D array with only 1 column and n rows.\r\n",
        "dataset[\"sexo\"] = imp_most_frequent.fit_transform(dataset[\"sexo\"].values.reshape(-1, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaoyxqeGBOK4"
      },
      "source": [
        "## Other columns\r\n",
        "With the above code we found out that only the sex column has 'NaN' values. However, when we first performed the inspection we could notice that many columns (regarding parent's information) have a custom string for missing values. We still can apply the above strategy to this columns.\r\n",
        "\r\n",
        "How can we solve this?\r\n",
        "\r\n",
        "A simple strategy is to first manually analyze the unknow string value for each column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPqRR-N7EnV9"
      },
      "source": [
        "# We manually construct a dictionary where each column (key) has the unknow value string (value)\r\n",
        "target_cols = {\"nomeconcelho\": \"SEM CONCELHO\",\r\n",
        "               \"paigse\": \"Desconhecido / N?o tem\",\r\n",
        "               \"painesc\" : \"Desconhecido\",\r\n",
        "               \"paiprofissao\" : \"Desconhece\",\r\n",
        "               \"maegse\" : \"Desconhecido / N?o tem\",\r\n",
        "               \"maenesc\" : \"Desconhecido\", \r\n",
        "               \"maeprofissao\" : \"Desconhece\"}\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXytoDjOEVQz"
      },
      "source": [
        "# Here we iterate over (key, value) pair in the previous dictionary\r\n",
        "# Each key ('column') is the column to be transformed\r\n",
        "# Each value ('unknow_value_string') is the value to replace\r\n",
        "for column, unknow_value_string in target_cols.items():\r\n",
        "  # Create custom imputer object for each column \r\n",
        "  imp_most_frequent = SimpleImputer(missing_values = unknow_value_string, strategy='most_frequent', verbose = 0)\r\n",
        "  # Perform the replacement (reshape is required to make the data a (n,1) array)\r\n",
        "  dataset[column] = imp_most_frequent.fit_transform(dataset[column].values.reshape(-1, 1))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f80zVpw9Paw"
      },
      "source": [
        "## 2.2 Transforming Categorical Columns\r\n",
        "First let's find out which columns have categorical (non-numeric) values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00nLUc119Zos",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd9ac0b3-5181-4a21-bf2c-b14f52508ba1"
      },
      "source": [
        "non_numeric_columns = dataset.columns.difference(dataset._get_numeric_data().columns).to_list()\r\n",
        "print(f\"Columns with categorical data: {non_numeric_columns}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Columns with categorical data: ['maegse', 'maenesc', 'maeprofissao', 'nomeconcelho', 'paigse', 'painesc', 'paiprofissao', 'sexo']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdcSm7wYCJRc"
      },
      "source": [
        "Now we should encode each of this columns to numeric. For this we will use the [One-Hot encoding technique](https://en.wikipedia.org/wiki/One-hot). Pandas provides us a high level API for this, where we only need to specify the list of columns that should be encoded (we already got this list)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l3mzNqPGohD"
      },
      "source": [
        "# Perform 'OneHotEncoding' for the all the categorical columns\r\n",
        "dataset = pd.get_dummies(dataset, columns=non_numeric_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wI44lfv792L9"
      },
      "source": [
        "We also need to split our dataframe, called `dataset`, into `X` and `y`:\r\n",
        "*   `X` should contain the dataset features;\r\n",
        "*   `y` should contain the dataset labels.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96mA4Hn8C5vT"
      },
      "source": [
        "# Extract the 'Dropout' ('Desistencia') column from X (features) to be used as target (y)\r\n",
        "X = dataset[dataset.columns.difference([\"Desistencia\"])]\r\n",
        "y = dataset[[\"Desistencia\"]]\r\n",
        "# Make sure y is an array\r\n",
        "y = np.array(y).ravel()\r\n",
        "\r\n",
        "# Save the feature names\r\n",
        "features_names = X.columns.values\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d_kSlREC0kH"
      },
      "source": [
        "## 2.3 Feature Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w60BjtUx-XD-"
      },
      "source": [
        "For neural networks it's really important and common practise to rescale the data to a common range. For this we can use [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) from scikit-learn, which removes the `mean`  and sets the `standard deviation` to 1.\r\n",
        "\r\n",
        "\r\n",
        "Notes:\r\n",
        "\r\n",
        "This procedure does not affect `RandomForests` performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IACPATKIOaOi"
      },
      "source": [
        "# Import the scaler for scikit-learn\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "\r\n",
        "# Scale the features\r\n",
        "X = StandardScaler().fit_transform(X)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVIP9amnnOn_"
      },
      "source": [
        "## 2.4 Splitting the dataset\r\n",
        "It's mandatory to not use the same data for training and validating the model. Therefore, K-Fold Cross-validation will be used. We can use the scikit-learn API [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z10IB0lnSqm"
      },
      "source": [
        "# Import the k-fold from scikit-learn\r\n",
        "from sklearn.model_selection import StratifiedKFold\r\n",
        "# The stratified means that the number of positive labels are distributed evenly trough the folds.\r\n",
        "\r\n",
        "# Object that performs shuffling and data splitting (10 folds)\r\n",
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQHuQi3cfwIa"
      },
      "source": [
        "# 3. Building the models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfYTKzdjfzYX"
      },
      "source": [
        "## 3.1 Random Forest\r\n",
        "To implement `RandomForests` we can use the scikit-learn [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html?highlight=randomforestclassifier)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbRSGq7Pf5CK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15c432f7-b772-4c1b-d94f-b713d3d45372"
      },
      "source": [
        "# Import the classifier and cross-validation method\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.model_selection import cross_validate\r\n",
        "\r\n",
        "# Create baseline (no parameters tuning (random_state is only for reproducible results))\r\n",
        "model = RandomForestClassifier(random_state=0)\r\n",
        "\r\n",
        "# Establish metrics that should be calculated\r\n",
        "scoring=['accuracy', 'roc_auc']\r\n",
        "\r\n",
        "# Perform cross-validation on the data\r\n",
        "# We pass the model, the data, scoring metrics and our custom cross-validation strategy\r\n",
        "results = cross_validate(model, X, y, scoring = scoring , cv = cv)\r\n",
        "\r\n",
        "# Results is a dictionary and we can extract the metrics results\r\n",
        "accuracy = results[\"test_accuracy\"]\r\n",
        "auc = results[\"test_roc_auc\"]\r\n",
        "\r\n",
        "# Print `mean` values from metrics and their `std` (standard deviation)\r\n",
        "print(f\"Accuracy: {accuracy.mean():.2f} (+/- {accuracy.std():.2f})\")\r\n",
        "print(f\"AUC: {auc.mean():.2f} (+/- {auc.std():.2f})\")\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.85 (+/- 0.05)\n",
            "AUC: 0.92 (+/- 0.06)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tdu3B2asftHS"
      },
      "source": [
        "## Inspecting the most important features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBgmgEszBjj1"
      },
      "source": [
        "`RandomForests` can be used to inspect the most important features in a dataset. \r\n",
        "\r\n",
        "Please note that this method can be misleading for high cardinality features (many unique values). Please check [PermutationImportance](https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html) as an alternative."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qb0z3JR2fpxH",
        "outputId": "08adf32b-6f42-4fd7-c2a9-6472a183a2d8"
      },
      "source": [
        "# Model needs to be re-fitted (trained again)\r\n",
        "model.fit(X,y)\r\n",
        "\r\n",
        "# Extract the feature importance\r\n",
        "importances = model.feature_importances_\r\n",
        "\r\n",
        "# Extract indices for sorting the importances\r\n",
        "indices = np.argsort(importances)[::-1]\r\n",
        "\r\n",
        "# Number of best features to show\r\n",
        "how_many_features = 8\r\n",
        "\r\n",
        "print(f\"Feature ranking (top {how_many_features}):\")\r\n",
        "for f in range(how_many_features):\r\n",
        "    print(f\"{f+1}. feature {features_names[indices[f]]} ({importances[indices[f]]})\")\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature ranking (top 8):\n",
            "1. feature SISTEMAS DIGITAIS (0.08721715124994979)\n",
            "2. feature ARQUITETURA DE COMPUTADORES (0.081328988253291)\n",
            "3. feature idade (0.0775741143167571)\n",
            "4. feature LABORATORIO INTEGRADO I (0.05880461380615652)\n",
            "5. feature ALGEBRA LINEAR (0.05051097417356697)\n",
            "6. feature ANALISE MATEMATICA I (0.04904704300055357)\n",
            "7. feature METODOLOGIAS DE PROGRAMAC?O I (0.040738948010107315)\n",
            "8. feature LOGICA COMPUTACIONAL (0.04072276826048913)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzdXEi9fnxaJ"
      },
      "source": [
        "## Tuning the parameters\r\n",
        "\r\n",
        "We can try to improve our model by tuning it's parameters. One way to achieve this is with [GridSearch](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). This algorithm performs an exhaustive search over specified parameters for a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJcNs74Dr-kM",
        "outputId": "73d8d280-7ddd-448c-d71c-04dcf3787fd7"
      },
      "source": [
        "# Import the model\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "\r\n",
        "# Define the parameter grid\r\n",
        "parameters = {'n_estimators': [ 50, 70, 90, 110],\r\n",
        "              'max_depth':[7, 10, 13, 16, 20]}\r\n",
        "\r\n",
        "# Build a new GridSearch model based on the previous RandomForest model (GridSearch itself implements the same interface as the RandomForest model)\r\n",
        "model = GridSearchCV(model, parameters, cv=cv, scoring=scoring, refit='roc_auc')\r\n",
        "# The refit parameter indicates the metric that should be used to choose the best model\r\n",
        "\r\n",
        "# Fit the data on model for performing the cross-validation\r\n",
        "model.fit(X, y)\r\n",
        "\r\n",
        "# Show best parameters\r\n",
        "print(f\"Best parameters: {model.best_params_}\")\r\n",
        "\r\n",
        "# Acess cross-validation results\r\n",
        "results = model.cv_results_ \r\n",
        "\r\n",
        "# Extract cross-validation metric results of the best model\r\n",
        "mean_acc = results[\"mean_test_accuracy\"][model.best_index_]\r\n",
        "std_acc = results[\"std_test_accuracy\"][model.best_index_]\r\n",
        "\r\n",
        "mean_auc = results[\"mean_test_roc_auc\"][model.best_index_]\r\n",
        "std_auc = results[\"std_test_roc_auc\"][model.best_index_]\r\n",
        "\r\n",
        "# Print the results\r\n",
        "print(f\"Accuracy: {mean_acc:.2f} (+/- {std_acc:.2f})\")\r\n",
        "print(f\"AUC: {mean_auc:.2f} (+/- {std_acc:.2f})\")\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best parameters: {'max_depth': 16, 'n_estimators': 50}\n",
            "Accuracy: 0.86 (+/- 0.03)\n",
            "AUC: 0.93 (+/- 0.03)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KHhHKS7PHKH"
      },
      "source": [
        "## 3.2 Neural Networks\r\n",
        "To implement neural networks we use [Tensorflow Keras](https://www.tensorflow.org/guide/keras). This API allows us to build complex neural networks easily."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U05BjcEQPNr"
      },
      "source": [
        "# Import tensorflow\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "# Define model architecture\r\n",
        "model = tf.keras.Sequential([\r\n",
        "    tf.keras.layers.Dense(8, input_shape=(X.shape[1],), activation='relu' ),\r\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\r\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid') # apenas um neurónio para output de 0 ou 1\r\n",
        "  ])\r\n",
        "\r\n",
        "# Compile the model\r\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\r\n",
        "                loss=tf.keras.losses.BinaryCrossentropy(),\r\n",
        "                metrics=[tf.keras.metrics.Accuracy(), \r\n",
        "                         tf.keras.metrics.AUC()])\r\n",
        "\r\n",
        "# Create lists for holding the metric values\r\n",
        "acc_per_fold=[] # accuracy\r\n",
        "auc_per_fold=[] # AUC\r\n",
        "\r\n",
        "# Tensorflow isn't compatible by default with our custom cross-validation object. So we need to perform the data splits and the cross-validation itself manually.\r\n",
        "# To do this we use a for loop and call the split method of our cross-validation object, which will return indices for training and testing in each iteration.\r\n",
        "# Then we use this indices for splitting the data.\r\n",
        "for train_idx, test_idx in cv.split(X, y):\r\n",
        "\r\n",
        "  # Train the model with the training indices\r\n",
        "  model.fit(X[train_idx], y[train_idx], epochs=75, verbose=0)\r\n",
        "    \r\n",
        "  # Evaluate the model with the testing indices\r\n",
        "  scores = model.evaluate(X[test_idx], y[test_idx], verbose=0)\r\n",
        "\r\n",
        "  # Save the accuracy value on the test data\r\n",
        "  acc_per_fold.append(scores[1])\r\n",
        "  # Save the AUC value on the test data\r\n",
        "  auc_per_fold.append(scores[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2mKPnB-VQHh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f3bec02-91c7-474f-fc89-cfc4ae9a7819"
      },
      "source": [
        "# Transform the lists into numpy arrays for calculations\r\n",
        "acc_per_fold=np.array(acc_per_fold)\r\n",
        "auc_per_fold=np.array(auc_per_fold)\r\n",
        "\r\n",
        "# Display the results\r\n",
        "print(f\"Accuracy: {acc_per_fold.mean():.2f} (+/- {acc_per_fold.std():.2f})\")\r\n",
        "print(f\"AUC: {auc_per_fold.mean():.2f} (+/- {auc_per_fold.std():.2f})\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Binary accuracy: 0.95 (+/- 0.05)\n",
            "Loss: 0.22 (+/- 0.14)\n",
            "AUC: 0.99 (+/- 0.02)\n",
            "Precision: 0.87 (+/- 0.15)\n",
            "Recall: 0.97 (+/- 0.07)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}